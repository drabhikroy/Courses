---
title: 'What the @*%# is Program Evaluation?'
author: Dr. Abhik Roy
output: 
 xaringan::moon_reader:
   css: xaringan-themer.css
   countIncrementalSlides: false
---

<style>

section {
    display: flex;
    display: -webkit-flex;
}

section p {
    margin: auto;
}

section {
    height: 600px;
    width: 60%;
    margin: auto;
    border-radius: 20px;
    background-color: #212121;
}

section p {
    text-align: center;
    font-size: 30px;
    background-color: #212121;
    border-radius: 20px;
    font-family: Roboto Condensed;
    font-style: bold;
    padding: 15px;
    color: #bff4ee;
}

div.a {
  text-align: center;
}

.center2 {
  margin: 0;
  position: absolute;
  top: 50%;
  left: 50%;
  -ms-transform: translate(-50%, -50%);
  transform: translate(-50%, -50%);
}

</style>

```{r setup, include=FALSE, purl=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(fontawesome)
library(here)
library(clt)
library(carData)
library(DT)
library(scales)
library(showtext)
font_add_google("Roboto Condensed", "roboto")
showtext_auto()
```

```{r echo = FALSE, purl=FALSE}
xaringanthemer::style_duo(
  primary_color = "#212121",
  secondary_color = "#bff4ee",
  table_row_border_color = "#212121",
  table_row_even_background_color = "#212121",
  footnote_font_size = "0.6em",
  header_font_google = xaringanthemer::google_font("Roboto Condensed", "700"),
  text_font_google   = xaringanthemer::google_font("Roboto Condensed", "400")
)
xaringanExtra::use_xaringan_extra(c("tile_view", "animate_css", "tachyons"))
```

```{r eval = TRUE, echo = FALSE}
unchecked <- as.character(fontawesome::fa("square", fill = "#b2d8d8"))

checked <- as.character(fontawesome::fa("check", fill = "#ffffff"))
```


# Before Starting

There are many types of evaluations (e.g. personnel, product, etc.) each with their own distinct purposes, approaches, and general outcomes. For the sake of this slideshow, we'll use the term **evaluation** to refer to **program evaluations**.

---

#  First things First: Evaluation is not 

  - research 
  
--

  or

--
  
  - assessment

```{r eval = TRUE, echo = FALSE, fig.align='center', out.width="50%"}
knitr::include_graphics(file.path(here::here(),"static", "slides", "img","notresearch.png"))
```

---

#  Assessment 

  - <span style='color:#c8acf4'>Asks</span> what is going on at this very moment?

--

  - <span style='color:#18fff9'>Provides</span> a snapshot that may be in conjunction with other snapshots to gain a basic picture.
	
--

  - Can be answered with a yes or no but only for "right now" 

--

  - Is a part of the evaluative process

---

#  Research 

  - <span style='color:#c8acf4'>Asks</span> *how so?* and *what are the general implications based on the sample?*

--

  - <span style='color:#18fff9'>Provides</span> information to propagate further research
	
--

  - Cannot be answered with a yes or no and is intended to propagate knowledge
	
--

  - Is generally disjoint from evaluation except in research methodology and design

---

# Evaluation is Based on

```{r, eval=TRUE, echo=FALSE}
tibble(
    
  association = c("<span style='color:#81b29a'>Validity</span>", 
                  "<span style='color:#e07a5f'>Reliability</span>"),
  
  intent = c("<span style='color:#81b29a'>the degree to which the variable measures what it is intended to measure</span>", 
             "<span style='color:#e07a5f'>the extent to which the measurements remain consistent over repeated tests of the same subject under identical conditions</span>")
    
  )  %>%
  kbl(col.names = c("standards associated with", "<i>with the intent to uncover</i>"),
      "html", 
      escape = FALSE,
      align = "ll") 
  
```

---

# Evaluation is Conducted to 

```{r, eval=TRUE, echo=FALSE}
tibble(
    
  purpose = c("<b>collect evidence</b>", 
              "<b>get to the truth</b>"),
  
  caveat = c("access to resources and data will be limited", 
             "an evaluation may never see the light of day")
    
  )  %>%
  kbl(col.names = c("", "<i>with the caveat that</i>"),
      "html", 
      escape = FALSE,
      align = "ll") 
  
```

---

#  So what is evaluation then? 

There are two overarching types

--

  - Informal

--

  - Formal

---

# Informal evaluation

You do this everyday!

.center2[
```{r eval = TRUE, echo = FALSE}
knitr::include_graphics("img/phdcomics1.png",
                        error = FALSE)
```
]

---

#  Formal evaluation 

.center2[
```{r eval = TRUE, echo = FALSE}
knitr::include_graphics("img/scriven.png",
                        error = FALSE)
```
]

.footnote[(Davidson, 2005; Scriven, 1991)]

---

# The In a Nutshell Evaluation Description

--

<br><br>
<div class="a">An evaluation tries to answer</a>
<br><br>

<div class="a" style="color:#2bd1fc;font-size: 1.6em;">
<b><i> does it work and why does it work?</i></b>
</div>

---

#  What do you have to do? 

- Think for yourself

- Be or become independent

- Have or learn the ability to map out a study from start to finish with the knowledge that it will likely not got to plan

- Adjust to stakeholder and environmental needs

- Understand and be comfortable with that fact that you will not have any content knowledge of a majority of programs you will evaluate


```{r eval = TRUE, echo = FALSE, fig.align='center', out.width="60%"}
knitr::include_graphics("img/phdcomics2.png",
                        error = FALSE)
```

---

# Evaluation Components

---

# The Three Aspects of Evaluation

--

- Criteria

--

- Standards

--

- Indicators

---

#  Criteria 

- <p style="color:#5ee1ba;">Definition</p> 

  - An assessment a program's ability to
achieve its intended outcomes (i.e. does what its supposed to do) AND
make a meaningful differences as a consequence to its operation.

--

<br>
- <p style="color:#e87965;">Example</p> 

  - A car may be worth buying if it meets the following criteria: it is reliable, has a five star safety rating, has good fuel consumption, and has the ability to self-park.

---

#  Standards

- <p style="color:#5ee1ba;">Definition</p> 

  - The levels of performance expressed as a rating or grade


--

<br>
- <p style="color:#e87965;">Examples</p>

  - *Quantitative*: Minimum of a 2.8 GPA to gain entrance into a graduate program
  
  - *Qualitative*: Performance in a thesis defense

---

#  Indicators

- <p style="color:#5ee1ba;">Definition</p> 

  - Aspects that can be measured within an evaluation that may tell us what is actually going on.

--

<br>
- <p style="color:#e87965;">Example</p>

  - The score on the Stanford-Binet test is an indicator of the IQ as a variable.

--

<br>
- <p style="color:#5ec7e1;">Note</p> 

  - Validity and reliability are not addressed here 
  
  - Indicators by themselves do not have to have these aspects.

---

# The Three Purposes of Evaluation

To determine

--

- Merit

--

- Worth

--

- Significance 

---
#  Merit 

- <span style='color:#dfbbbb'>Synonymous</span> with **Quality**

--

- <span style='color:#c8acf4'>Asks</span> *does something do well in what it is supposed to do?*

--

- <p style="color:#e87965;">Example</p>

  - *Question*: Does the SNA course succeed in building an understanding of the content and practice of social networks?
  
  - *Outcome*: If so, it probably has merit. Otherwise likely not

---

#  Worth 

- <span style='color:#dfbbbb'>Synonymous</span> with **Value**

--

- <span style='color:#c8acf4'>Asks</span> *how valuable is this and to whom?* 

--

- <p style="color:#e87965;">Example</p>

  - *Question*: Do students who pass the SNA course tend to use social network analysis in their future work?
  
  - *Outcome*: If so, it probably has worth. Otherwise likely not

---

#  Significance 

- <span style='color:#dfbbbb'>Synonymous</span> with **Importance**

--

- <span style='color:#c8acf4'>Asks</span> *how important is this and to whom?*

--

- <p style="color:#e87965;">Example</p>

  - *Question*: Is the SNA course necessary for the sustainability of qualified methodologists in the United States?
  
  - *Outcome*: If so, it probably has significance. Otherwise likely not

---

#  One Caveat! 

- Most evaluation questions are not so black and white

--

- They include some parts of merit, worth, and significance which are often used as clues

---

#  An evaluation is generally… 

- based on values (often of the person or people paying you)

--

- erratic (both in practice and work life)

--

- not well defined (and cannot be since you're dealing with people!)

--

- political

---

#  Private evaluation work is… 

```{r, eval=TRUE, echo=FALSE}

tibble(
    
  positive = c("it can be extremely lucrative", 
               "you can pick and choose what you wish to study and like working  solo",
               "you may get to travel",
               "",
               "",
               "",
               "",
               ""),
  
  good = c("are able to work with a diverse set of people", 
           "are ethical",
           "can adjust their writing and comminication based on type of audience",
           "have a strong methodological background",
           "enjoy diversity in content",
           "leave biases at the door",
           "love and thrive in uncertainty",
           "work well in a specified timeframe"
           )
    
  )  %>%
  kbl(col.names = c("positive in that", "good for people who"),
      "html", 
      escape = FALSE,
      align = "ll") 
  
```

---

#  Public evaluation work is… 

```{r, eval=TRUE, echo=FALSE}

tibble(
    
  positive = c("you get to have a standard 40-hour workweek", 
               "you do not have to compete for studies and like working  solo",
               "you often get to stay within your home region",
               "",
               "",
               "",
               "",
               ""),
  
  good = c("are able to work with the same people everyday", 
           "are ethical",
           "can write and communicate well to limited audiences",
           "have strengths in certain methodological areas",
           "enjoy homogeneity in content",
           "understand that personal biases are part of the job",
           "love and thrive in certainty",
           "work well in a longer timeframe"
           )
  )  %>%
  kbl(col.names = c("positive in that", "good for people who"),
      "html", 
      escape = FALSE,
      align = "ll") 
  
```

---

# Primary Purposes

--

- **Formative**: Conducted with the intent to improve

--

- **Summative**: Conducted with the intent to inform decision making and/or determine judgement

---

# Common Types

- **Needs Assessment**: <span style='color:#c8acf4'>Asks</span> *what are the needs of stakeholders and/or sponsors?*

--

- **Process**: <span style='color:#c8acf4'>Asks</span> *is a program doing what it says its doing?*

--

- **Outcomes**: <span style='color:#c8acf4'>Asks</span> *what is degree to which the program is having an effect on the target population’s behaviors?*

--

- **Impact**: <span style='color:#c8acf4'>Asks</span> *what is the degree the degree to which the program meets its goal(s)?*

---

# The Evaluator's Roaddmap: A Logic Model 

- A logic model is a graphic depiction akin to a road map that presents the shared relationships among the resources, activities, outputs, outcomes, and impact for your program. It is intended to depict the relationship between your program’s activities and its intended effects (CDC, 2018)

--

- You can display change within a program by filling one out before an evaluation commences and after its conclusion, respectively

---

# Linear example

```{r eval = TRUE, echo = FALSE, fig.align='center'}
knitr::include_graphics("img/blanklm.png",
                        error = FALSE)
```

.footnote[Many other variants can be found at repositories like those at the [University of Wisconsin-Madison Division of Extension](https://fyi.extension.wisc.edu/programdevelopment/logic-models/)]

---

#  Logic Model Terms		 

```{r eval = TRUE, echo = FALSE, fig.align='center'}
knitr::include_graphics("img/lmterms.png",
                        error = FALSE)
```

---

#  Example: Logic Model

```{r eval = TRUE, echo = FALSE, fig.align='center'}
knitr::include_graphics("img/examplelm.png",
                        error = FALSE)
```

.footnote[<span style="color:#5ec7e1;">Note:</span> This is a subset of a much larger model]

---

#  What Evaluation is Like 

.center2[
```{r eval = TRUE, echo = FALSE}
knitr::include_graphics("img/phdcomics3.png",
                        error = FALSE)
```
]

---

# References 

+ Centers for Disease Control and Prevention, Program Performance and Evaluation Office. (2019, May 7). Logic Models. [https://www.cdc.gov/eval/logicmodels/index.htm](https://www.cdc.gov/eval/logicmodels/index.htm)

+ Davidson, E. J. (2005). *Evaluation methodology basics: The nuts and bolts of sound evaluation*. Sage.

+ Scriven, M. (1991). *Evaluation thesaurus* (4th ed.). Sage.


---

# Acknowledgement

Cartoons were created and are owned by Chris Lysy. To see more of his work including those included in this slideshow, please head over to [So what is evaluation anyway?](https://freshspectrum.com/what-is-evaluation-anyway/)

---

#  Thank you! 

Questions and/or comments may be sent to [Abhik.Roy@mail.wvu.edu](mailto:Abhik.Roy@mail.wvu.edu)

You may also stop by Allen Hall 504O if you prefer a face-to-face chat


